* Code and data for the Digital Multiplex Ligation Assay (dMLA) method validation

** Data files

 | File                    | Content                                  |
 |-------------------------+------------------------------------------|
 | Allele-dna.fa           | Reference sequences                      |
 | Allele.tab              | Sequence annotation                      |
 | all_probes.xlsx         | Probe, template and primer sequences     |
 | expanded_libraries.xlsx | Annotation for Figures 3 and S01         |
 | libraries.xlsx          | Annotation for Figures 3 and S01         |
 | mol_bc_counts.tar.gz    | Molecular counts from the sequence files |
 | probes.xlsx             | Probe, template and primer sequences     |



* 1) Figure 2

** Sequencing stats

In /Users/mavatam/Dropbox/Scratch/MLA/2nd

*** Raw

#+BEGIN_SRC sh
ls *.gz | while read file; do echo $file; gzcat $file | wc -l | awk '{print $1 / 4}'; done
#+END_SRC

NG-17872_10_lib297291_6185_1_1.fastq.gz 6802543
NG-17872_10_lib297291_6185_1_2.fastq.gz 6802543
NG-17872_11_lib297292_6178_3_1.fastq.gz 3873555
NG-17872_11_lib297292_6178_3_2.fastq.gz 3873555
NG-17872_11_lib297292_6189_3_1.fastq.gz 5111334
NG-17872_11_lib297292_6189_3_2.fastq.gz 5111334

Or

lib10 6802543
lib11_1 3873555
lib11_2 5111334

*** After read merging

#+BEGIN_SRC sh
ls *.fastq | while read file; do echo $file; wc -l $file | awk '{print $1 / 4}'; done
#+END_SRC

lib10.fastq 6731594
lib11_1.fastq 3677900
lib11_2.fastq 4837779

*** After quality filtering

#+BEGIN_SRC sh
ls lib*.fasta | while read file; do echo $file; grep -c ">" $file; done
#+END_SRC

lib10.fasta 6696375
lib11_1.fasta 3648867
lib11_2.fasta 4802951

*** Put together

|---------+---------+---------------+----------------------|
| Library |     Raw | After merging | After quality filter |
|---------+---------+---------------+----------------------|
| lib10   | 6802543 |       6731594 |              6696375 |
| lib11_1 | 3873555 |       3677900 |              3648867 |
| lib11_2 | 5111334 |       4837779 |              4802951 |
|---------+---------+---------------+----------------------|



** Join the paired ends and quality filter using nsearch

|-----------------------------------------+---------------|
| Inputs                                  | Outputs       |
|-----------------------------------------+---------------|
| NG-17872_10_lib297291_6185_1_1.fastq.gz | lib10.fasta   |
| NG-17872_11_lib297292_6178_3_1.fastq.gz | lib11_1.fasta |
| NG-17872_11_lib297292_6189_3_1.fastq.gz | lib11_2.fasta |
| NG-17872_10_lib297291_6185_1_1.fastq.gz |               |
| NG-17872_11_lib297292_6178_3_1.fastq.gz |               |
| NG-17872_11_lib297292_6189_3_1.fastq.gz |               |
|-----------------------------------------+---------------|

 #+BEGIN_SRC sh
 nsearch merge --forward NG-17872_10_lib297291_6185_1_1.fastq.gz --reverse NG-17872_10_lib297291_6185_1_2.fastq.gz --out lib10.fastq
 nsearch merge --forward NG-17872_11_lib297292_6178_3_1.fastq.gz --reverse NG-17872_11_lib297292_6178_3_2.fastq.gz --out lib11_1.fastq
 nsearch merge --forward NG-17872_11_lib297292_6189_3_1.fastq.gz --reverse NG-17872_11_lib297292_6189_3_2.fastq.gz --out lib11_2.fastq

 nsearch filter --in lib10.fastq --out lib10.fasta
 nsearch filter --in lib11_1.fastq --out lib11_1.fasta
 nsearch filter --in lib11_2.fastq --out lib11_2.fasta
 #+END_SRC


** Then process the merged, quality-filtered sequences into count tables on Python

|---------------+-------------|
| Inputs        | Outputs     |
|---------------+-------------|
| lib10.fasta   | lib10.csv   |
| lib11_1.fasta | lib11_1.csv |
| lib11_2.fasta | lib11_2.csv |
| probes.xlsx   |             |
|---------------+-------------|


TMP

#+BEGIN_SRC ipython :session

import epride as ep
import pandas as pd
import glob
from collections import defaultdict

fasta_files = glob.glob("lib*.fasta")

fname = "lib10.fasta"

def get_lengths(fname):
    out_name = fname.split(".")[0] + "_lengths.csv"
    len_acc = defaultdict(int)
    for _, seq in ep.read_fasta(fname):
        len_acc[len(seq)] += 1
    out_tbl = pd.DataFrame([[i, j] for i, j in len_acc.items()], columns=['Length', 'Count'])
    out_tbl['File'] = fname
    out_tbl.to_csv(out_name, index=False)

for fname in fasta_files:
    get_lengths(fname)

#+END_SRC


TMP

#+BEGIN_SRC R :session

library(tidyverse)
library(fs)

dir_ls(path = '../MLA/2nd/', glob='*lengths.csv') %>% 
    tibble(fname = .) %>% 
    mutate(data = map(fname, read_csv)) %>% 
    unnest(data) %>% 
    select(-fname) %>% 
    ggplot(aes(x = Length, y = Count, color = File)) +
    geom_density(stat = "identity")

#+END_SRC

 #+BEGIN_SRC python
 import os
 import epride as ep
 import pandas as pd
 from collections import defaultdict

 ## Import the data

 probes = pd.ExcelFile("probes.xlsx").parse('probes')
 pcr_bcs = pd.ExcelFile("probes.xlsx").parse('pcr_barcodes').drop('Sequence', axis=1)
 other_sequences = pd.ExcelFile("probes.xlsx") \
                     .parse('other_primers_and_sequences') \
                     .set_index('Sequence_name')
 left_side = other_sequences.loc['for_primer_5', 'Sequence']
 middle = other_sequences.loc['left_probe_5', 'Sequence']
 right_side = other_sequences.loc['rev_primer_rc', 'Sequence'][:20]


 ## Create the template, sample id and bc number dictionaries

 template_dictionary = {}
 for _, row in probes.iterrows():
     for seq in ep.expand_primers(row['Target']):
         template_dictionary[seq] = row['Short_name']

 sample_id_dict = {bc: bc_id for _, (_, bc_id, bc) in pcr_bcs.iterrows()}

 sample_ix_dict = {bc: ix for _, (ix, _, bc) in pcr_bcs.iterrows()}


 ## Define the sequence parser

 def seq_parser(fasta_file):
     for seq_id, seq in ep.read_fasta(fasta_file):
         if (len(seq) > 133 or len(seq) < 140) and \
         seq.count(left_side) == 1 and \
         seq.count(middle) == 1 and \
         seq.count(right_side) == 1:
             cluster_id = ''
             try:
                 fst_half, long_mid_part = seq.split(middle)
                 _, bc = fst_half.split(left_side)
                 mid_part, _ = long_mid_part.split(right_side)
                 mol_id = mid_part[-10:]
                 cluster_id = mid_part[8:-10]
                 if bc in sample_id_dict:
                     sample_id = sample_id_dict[bc]
                     sample_ix = sample_ix_dict[bc]
             except ValueError:
                 pass
             if cluster_id in template_dictionary:
                 cluster = template_dictionary[cluster_id]
                 yield [sample_ix, sample_id, cluster, mol_id]

 ## And parse the sequences into pandas DataFrames

 lib10 = pd.DataFrame(seq_parser("lib10.fasta"),
                      columns=['Sample_ix',
                               'Sample_id',
                               'Cluster',
                               'Molecule_id'])

 lib11_1 = pd.DataFrame(seq_parser("lib11_1.fasta"),
                        columns=['Sample_ix',
                                 'Sample_id',
                                 'Cluster',
                                 'Molecule_id'])

 lib11_2 = pd.DataFrame(seq_parser("lib11_2.fasta"),
                        columns=['Sample_ix',
                                 'Sample_id',
                                 'Cluster',
                                 'Molecule_id'])

 ## And write out as csvs

 lib10.to_csv("lib10.csv", index=False)
 lib11_1.to_csv("lib11_1.csv", index=False)
 lib11_2.to_csv("lib11_2.csv", index=False)

 #+END_SRC

 
** Expand the library file (which lists the gene families present in the bacterial genomic DNA samples)

|----------------+-------------------------|
| Inputs         | Outputs                 |
|----------------+-------------------------|
| libraries.xlsx | expanded_libraries.xlsx |
|----------------+-------------------------|

#+BEGIN_SRC ipython :session
import os
import epride as ep
import pandas as pd
from collections import defaultdict

## Import the data

libraries = pd.read_excel("libraries.xlsx")

## Expand the table based in the numeric Cluster column

acc = []
for _, row in libraries.iterrows():
    cluster = row['Cluster']
    if isinstance(cluster, int):
        row1 = row.copy().to_dict()
        row2 = row.copy().to_dict()
        row1['Cluster'] = str(cluster) + "_1"
        row2['Cluster'] = str(cluster) + "_2"
        acc.append(row1)
        acc.append(row2)
    elif "," in cluster:
        exp_cluster = cluster.split(",")
        for cluster_instance in exp_cluster:
            try:
                cluster_instance = int(cluster_instance)
                row1 = row.copy().to_dict()
                row2 = row.copy().to_dict()
                row1['Cluster'] = str(cluster_instance) + "_1"
                row2['Cluster'] = str(cluster_instance) + "_2"
                acc.append(row1)
                acc.append(row2)
            except ValueError:
                pass

exp_libraries = pd.DataFrame(acc)[['Number',
                                   'Sample_ID',
                                   'Genes',
                                   'Cluster',
                                   'Probes_in_MM_included',
                                   'Sample_ix',
                                   'Tube']]

exp_libraries.to_excel("expanded_libraries.xlsx", index=False)
#+END_SRC


** Prepare visualizations of the lib10 and lib11 count tables

|-------------------------+------------------|
| Inputs                  | Outputs          |
|-------------------------+------------------|
| expanded_libraries.xlsx | lib_complete.pdf |
| lib10.csv               |                  |
| lib11_1.csv             |                  |
| lib11_2.csv             |                  |
|-------------------------+------------------|

 #+BEGIN_SRC R :session
 library(tidyverse)
 library(readxl)

 ## Prepare count table for tube 10

 lib10_counts <-
     read_csv("lib10.csv") %>%
     unique %>%
     group_by(Sample_ix, Cluster) %>%
     summarise(n=n()) %>%
     spread(key=Cluster, value=n, fill=0) %>%
     ungroup %>%
     mutate(Sample_ix = as.factor(Sample_ix)) %>%
     gather(Cluster, Count, -Sample_ix) %>%
     mutate(Tube = 10) %>%
     select(Tube, Sample_ix, Cluster, Count)

 ## Prepare count table for tube 11

 lib11_counts <-
     rbind(
         read_csv("lib11_1.csv"),
         read_csv("lib11_2.csv")) %>%
     unique %>%
     group_by(Sample_ix, Cluster) %>%
     summarise(n=n()) %>%
     spread(key=Cluster, value=n, fill=0) %>%
     ungroup %>%
     mutate(Sample_ix = as.factor(Sample_ix)) %>%
     gather(Cluster, Count, -Sample_ix) %>%
     mutate(Tube = 11) %>%
     select(Tube, Sample_ix, Cluster, Count)

 ## Merge the count tables

 lib_counts <-
     rbind(lib10_counts, lib11_counts) %>%
     spread(Cluster, Count, fill=0) %>%
     gather(Cluster, Count, -Tube, -Sample_ix)  %>%
     spread(Sample_ix, Count, fill=0) %>%
     gather(Sample_ix, Count, -Tube, -Cluster)
 

 ## Prepare a logical mask of the sample design

 design <-
     read_excel("expanded_libraries.xlsx") %>%
     mutate(Entry = 1) %>%
     select(Tube, Cluster, Tube, Sample_ix, Entry) %>%
     unique %>%
     spread(Cluster, Entry, fill=0) %>%
     mutate(Sample_ix = as.factor(Sample_ix)) %>%
     gather(Cluster, Count, -Sample_ix, -Tube) %>%
     mutate(Mask = Count > 0) %>%
     select(-Count)

 ## Merge the logical mask with the count tables

 full_lib <-
     left_join(lib_counts,
               design,
               by=c("Tube", "Sample_ix", "Cluster")) %>%
     mutate_if(is.logical, replace_na, FALSE) %>%
     mutate(Cluster = as.factor(Cluster))

 ## Plot as a heatmap and reverse the false positives for visual identification

 full_lib %>% 
     mutate(Count = ifelse(Mask, Count, -Count),
            Tube = as.factor(Tube)) %>%
     ggplot(aes(x=Cluster, y=Sample_ix)) +
     geom_tile(aes(fill=Count), color="gray") +
     facet_grid(Tube~.) +
     scale_fill_gradient2(low = "blue", high = "red", mid="white") +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=5))
 ggsave("lib_complete.pdf", last_plot())
 
 ## Summarise the clusters per sample per tube

 cluster_summary <-
     filter(full_lib, Count > 500) %>%
     separate(Cluster, into=c("Cluster_no", "Cluster_repl"), sep="_") %>%
     select(-Cluster_repl, -Mask, -Count) %>%
     group_by(Tube, Sample_ix) %>%
     summarise(Clusters = paste(unique(Cluster_no), collapse=","))
 write_delim(cluster_summary, "cluster_summary.csv", delim=";")


 t10_dl <- 
     filter(full_lib, Tube == 10,
            Sample_ix %in% c(511, 512, 513)) %>%
     group_by(Cluster) %>% 
     summarise(mean_cnt = mean(Count, na.rm = TRUE),
               sd_cnt = sd(Count, na.rm = TRUE),
               ld = mean_cnt + 3*sd_cnt)

 full_lib %>% 
     filter(Tube == 10) %>% 
     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
     left_join(t10_dl, by="Cluster") %>%
     ungroup %>% 
     mutate(Signal = ifelse(Count > ld, 1, 0),
            Sample_ix = as.factor(Sample_ix),
            Signal = ifelse(Mask, Signal, -Signal)) %>% 
     ggplot(aes(x=Cluster, y=Sample_ix)) +
     geom_tile(aes(fill=Signal)) +
     scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))

 ggsave("interm1.pdf", last_plot())

 full_lib %>% 
     filter(Tube == 10) %>% 
     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
     left_join(t10_dl, by="Cluster") %>%
     ungroup %>% 
     mutate(Signal = ifelse(Count > ld, 1, 0),
            Sample_ix = as.factor(Sample_ix)) %>% 
     separate(Cluster, c("Clust", "Repl"), by="_") %>%
     group_by(Sample_ix, Clust) %>%
     mutate(Signal = ifelse(sum(Signal) == 2, 1, 0),
            Signal = ifelse(Mask, Signal, -Signal)) %>% 
     ggplot(aes(x=Clust, y=Sample_ix)) +
     geom_tile(aes(fill=Signal)) +
     scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))

 ggsave("final1.pdf", last_plot())



 clust_conv <- 
     read_xlsx("Table_Gates_ProbeTargets.xlsx") %>%
     select(Cluster, `Enzyme family`) %>%
     filter(complete.cases(.)) %>%
     rename(Clust = Cluster,
            Family = `Enzyme family`)


 full_lib %>% 
     filter(Tube == 10) %>% 
     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
     left_join(t10_dl, by="Cluster") %>%
     ungroup %>% 
     mutate(Signal = ifelse(Count > ld, 1, 0),
            Sample_ix = as.numeric(Sample_ix)) %>% 
     separate(Cluster, c("Clust", "Repl"), by="_") %>%
     group_by(Sample_ix, Clust) %>%
     mutate(Signal = ifelse(sum(Signal) == 2, 1, 0),
            Signal = ifelse(Mask, Signal, -Signal)) %>%
     ungroup %>%
     mutate(Clust = as.numeric(Clust)) %>% 
     left_join(read_xlsx("sample_conversion.xlsx")) %>%
     left_join(clust_conv) %>% 
     ggplot(aes(x=Family, y=Sample_ID)) +
     geom_tile(aes(fill=Signal)) +
     scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))
 ggsave("final1.pdf", last_plot())

 full_lib %>% 
     filter(Tube == 10) %>% 
     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
     left_join(t10_dl, by="Cluster") %>%
     ungroup %>% 
     mutate(Signal = ifelse(Count > ld, 1, 0),
            Sample_ix = as.numeric(Sample_ix)) %>% 
     separate(Cluster, c("Clust", "Repl"), by="_") %>%
     group_by(Sample_ix, Clust) %>%
     mutate(Signal = ifelse(sum(Signal) == 2, 1, 0)) %>%
     ungroup %>%
     mutate(Clust = as.numeric(Clust)) %>% 
     left_join(read_xlsx("sample_conversion.xlsx")) %>%
     left_join(clust_conv) %>%
     select(-Tube, -Repl, -Count, -Mask, -mean_cnt, -sd_cnt, -ld) %>%
     filter(Signal == 1) %>%
     write_csv("double_positives.csv")

 full_lib %>% 
     filter(Tube == 10) %>% 
     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
     left_join(t10_dl, by="Cluster") %>%
     ungroup %>% 
     mutate(Signal = ifelse(Count > ld, 1, 0),
            Sample_ix = as.numeric(Sample_ix)) %>% 
     separate(Cluster, c("Clust", "Repl"), by="_") %>%
     group_by(Sample_ix, Clust) %>%
     mutate(Signal = ifelse(sum(Signal) == 2, 1, 0),
            Signal = ifelse(Mask, Signal, -Signal)) %>% 
     ungroup %>% 
     mutate(Clust = as.factor(as.numeric(Clust)),
            Sample_ix = as.factor(Sample_ix)) %>% 
     ggplot(aes(x=Clust, y=Sample_ix)) +
     geom_tile(aes(fill=Signal)) +
     scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))
 ggsave("final2.pdf", last_plot())



 conf_mask <-
     read_xlsx("cluster_confirmation4.xlsx") %>% 
     gather(Cf, Conf, -Sample_ix, -False1, -False2, -False3) %>%
     select(-Cf) %>%
     gather(Fl, False_pos, -Sample_ix, -Conf) %>%
     select(-Fl) %>%
     filter(!(is.na(Conf) & is.na(False_pos))) %>%
     unique %>%
     mutate(Category = case_when(
                !is.na(Conf) ~ 3,
                !is.na(False_pos) ~ 4)) %>%
     gather(Type, Clust, -Sample_ix, -Category) %>%
     filter(complete.cases(.)) %>%
     select(-Type)


 signal_tbl <- 
     full_lib %>% 
     filter(Tube == 10) %>% 
     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
     left_join(t10_dl, by="Cluster") %>%
     ungroup %>% 
     mutate(Signal = ifelse(Count > ld, 1, 0),
            Sample_ix = as.numeric(Sample_ix)) %>% 
     separate(Cluster, c("Clust", "Repl"), sep="_") %>%
     group_by(Sample_ix, Clust) %>%
     mutate(Signal = ifelse(sum(Signal) == 2, 1, 0),
            Signal = ifelse(Mask, Signal, -Signal)) %>%
     ungroup %>%
     mutate(Clust = as.numeric(Clust)) %>%
     full_join(conf_mask) %>%
     left_join(read_xlsx("sample_conversion.xlsx")) %>%
     left_join(clust_conv) %>%
     select(-mean_cnt, -sd_cnt, -ld) %>% 
     mutate(Sign = case_when(
                Signal == -1 ~ 2,
                is.na(Category) ~ Signal,
                !is.na(Category) ~ Category),
            Sign = ifelse(Signal == 0, 0, Sign),
            Sign = as.factor(Sign))


 ggplot(signal_tbl, aes(x=Family, y=Sample_ID)) +
     geom_tile(aes(fill=Sign)) +
     scale_fill_manual(values = c("white", "red", "blue", "green", "orange")) +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))
 ggsave("final5.pdf", last_plot())
 
 ggplot(signal_tbl, aes(x=Family, y=Sample_ID)) +
     geom_tile(aes(fill=Sign)) +
     scale_fill_manual(values = c("white", "red", "blue", "green", "orange")) +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))

 ggsave("final4.pdf", last_plot())

 signal_tbl %>%
     mutate(Clust = as.factor(Clust),
            Sample_ix = as.factor(Sample_ix)) %>% 
     ggplot(aes(x=Clust, y=Sample_ix)) +
     geom_tile(aes(fill=Sign)) +
     scale_fill_manual(values = c("white", "red", "blue", "green", "orange")) +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))

 ggsave("overlaid.pdf", last_plot())

 signal_tbl %>%
     mutate(Clust = as.factor(Clust),
            Sample_ix = as.factor(Sample_ix),
            Signal = as.factor(Signal)) %>% 
     ggplot(aes(x=Clust, y=Sample_ix)) +
     geom_tile(aes(fill=Signal)) +
     scale_fill_manual(values = c("blue", "white", "red")) +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=7))
 ggsave("non_overlaid.pdf", last_plot())

 full_lib %>% 
     mutate(Count = ifelse(Mask, Count, -Count),
            Tube = as.factor(Tube)) %>% 
     filter(Tube == 10) %>% 
     separate(Cluster, c("Clust", "Repl"), by="_") %>% 
     mutate(Sample_ix = as.numeric(Sample_ix),
            Clust = as.numeric(Clust),
            Count = abs(Count)) %>%
     left_join(read_xlsx("sample_conversion.xlsx")) %>%
     left_join(clust_conv) %>% 
     filter(Repl != 3,
            Family != "KPC") %>% 
     unite(Fam_rep, Family, Repl, sep=" replicate") %>% 
     ggplot(aes(x=Fam_rep, y=Sample_ID)) +
     geom_tile(aes(fill=Count), color="gray") +
     scale_fill_gradient2(low = "blue", high = "red", mid="white") +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=5))
 ggsave("raw.pdf", last_plot())

 
 lib1 <- 
     full_lib %>% 
     mutate(Count = ifelse(Mask, Count, -Count),
            Tube = as.factor(Tube)) %>% 
     filter(Tube == 10) %>% 
     separate(Cluster, c("Clust", "Repl"), sep="_") %>% 
     mutate(Sample_ix = as.numeric(Sample_ix),
            Clust = as.numeric(Clust),
            Count = abs(Count)) %>%
     left_join(read_xlsx("sample_conversion.xlsx")) %>%
     left_join(clust_conv) %>% 
     filter(Repl != 3,
            Family != "KPC") %>% 
     select(Family, Repl, Sample_ID, Count)


 
 signal_tbl2 <- 
     full_lib %>% 
     filter(Tube == 10) %>% 
     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
     left_join(t10_dl, by="Cluster") %>%
     ungroup %>% 
     mutate(Signal = ifelse(Count > ld, 1, 0),
            Sample_ix = as.numeric(Sample_ix)) %>% 
     separate(Cluster, c("Clust", "Repl"), sep="_") %>%
     group_by(Sample_ix, Clust) %>%
     mutate(Signal = ifelse(sum(Signal) == 2, 1, 0),
            Signal = ifelse(Mask, Signal, -Signal)) %>%
     ungroup %>%
     mutate(Clust = as.numeric(Clust)) %>%
     full_join(conf_mask) %>%
     left_join(read_xlsx("sample_conversion.xlsx")) %>%
     left_join(clust_conv) %>%
     mutate(Sign = case_when(
                Signal == -1 ~ 2,
                is.na(Category) ~ Signal,
                !is.na(Category) ~ Category),
            Sign = ifelse(Signal == 0, 0, Sign),
            Sign = as.factor(Sign))



 left_join(lib1, signal_tbl2) %>% 
     unite(Fam_rep, Family, Repl, sep=" replicate") %>% 
     mutate(Signal = abs(Signal)) %>% 
     ggplot(aes(x=Sample_ID, y=Count, fill = Signal)) +
     geom_bar(stat = "identity") +
     geom_hline(aes(yintercept = ld), alpha = 0.1) + 
     facet_grid(Fam_rep ~ ., scales = "free") +
     theme(strip.text.y = element_text(angle = 0, size = 6),
           axis.text.x = element_text(angle = 45, hjust = 1, size = 3),
           axis.text.y = element_text(size = 3),
           panel.grid.major = element_blank(),
           panel.grid.minor = element_blank(),
           panel.border = element_blank(),
           panel.background = element_blank())

 ggsave("Fig_bar.pdf", last_plot())
 

 left_join(lib1, lib2) %>% 
     unite(Fam_rep, Family, Repl, sep=" replicate") %>% 
     ggplot(aes(x=Fam_rep, y=Sample_ID)) +
     geom_tile(aes(fill=Count, color=Sign), size=1) +
     scale_fill_gradient2(low = "blue", high = "red", mid="white") +
     theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=5))
 ggsave("raw_joined.pdf", last_plot())

 
 left_join(lib1, lib2) %>% 
     unite(Fam_rep, Family, Repl, sep=" replicate") %>%
     filter(complete.cases(.),
            Sign != 0) %>%
     pull(Sample_ID)

 left_join(lib1, lib2) %>% 
     unite(Fam_rep, Family, Repl, sep=" replicate") %>%
     pull(Sample_ID) %>%
     unique %>%
     length
 

 #+END_SRC


* 2) Figure S01 

** Prepare the 40-mer probe candidates
   
|---------------+-------------------|
| Inputs        | Outputs           |
|---------------+-------------------|
| Allele-dna.fa | probe_cands.fasta |
|---------------+-------------------|

 #+BEGIN_SRC R
 library(tidyverse)
 library(readxl)
 library(Biostrings)
 library(igraph)
 library(DECIPHER)
 library(stringi)
 library(glue)
 library(readxl)

 sliding_window <- function(sequence, win_size=20)
 {
     win_size <- win_size - 1
     split_sequence <- strsplit(sequence, split="")[[1]]
     num_chunks <- length(split_sequence) - win_size
     acc <- vector(mode = "character",
                   length = num_chunks)
     for (i in 1:num_chunks)
     {
         sub_seq <- paste(split_sequence[i : (i + win_size)],
                          collapse = "")
         acc[i] <- sub_seq
     }
     acc
 }

 deg_list <-
     list(
         'A' = 'A',
         'T' = 'T',
         'G' = 'G',
         'C' = 'C',
         '-' = '-',
         'W' = c('A', 'T'),
         'S' = c('C', 'G'),
         'M' = c('A', 'C'),
         'K' = c('G', 'T'),
         'R' = c('A', 'G'),
         'Y' = c('C', 'T'),
         'B' = c('C', 'G', 'T'),
         'D' = c('A', 'G', 'T'),
         'H' = c('A', 'C', 'G'),
         'V' = c('A', 'C', 'T'),
         'N' = c('A', 'C', 'G', 'T'))

 expand_seq <- function(seq)
 {
     seq_lst <-
         strsplit(seq, "") %>%
         unlist %>%
         map(~deg_list[[.x]]) %>%
         purrr::reduce(~as.vector(outer(.x, .y, paste, sep="")))
     if (identical(seq_lst, character(0)))
     {
         stop("Not a DNA sequence!")
     } else {
         seq_lst
     }
 }

 fasta_to_df <- function(filename)
 {
     fasta <- readDNAStringSet(filename)
     seqs <- as.character(fasta)
     names(seqs) <- NA
     tibble(Name = names(fasta),
            Sequence = seqs)
 }
 
 primer_candidates <-
     fasta_to_df("Allele-dna.fa") %>% 
     mutate(Exp = map(Sequence,
                      sliding_window(as.character,
                                     win_size = 40))) %>%
     select(-Sequence) %>%
     unnest(Exp) %>%
     group_by(Name) %>%
     mutate(Ix = row_number()) %>%
     separate(Name, into=c("Prot_id"), sep=" ") %>%
     unite(Fasta_id, Prot_id, Ix, sep="_")

 primer_candidates %>% 
     mutate(Out = glue(">{Fasta_id}\n{Exp}\n")) %>% 
     pull(Out) %>%
     write("probe_cands.fasta")
 #+END_SRC


** Prepare the BLAST search table

|-------------------+----------------|
| Inputs            | Outputs        |
|-------------------+----------------|
| probe_cands.fasta | probe_hits.csv |
| Allele-dna.fa     |                |
|-------------------+----------------|

 #+BEGIN_SRC sh 
 nsearch search --query=probe_cands.fasta --db=Allele-dna.fa --out=probe_hits.csv --min-identity=0.8 --strand=both --max-hits=1558
 #+END_SRC


** Then parse the resulting output file "probe_hits.csv" using a memory-efficient Python script

|----------------+------------------|
| Inputs         | Outputs          |
|----------------+------------------|
| probe_hits.csv | probe_counts.csv |
|----------------+------------------|

 #+BEGIN_SRC python
 import sys
 from collections import defaultdict

 acc = defaultdict(int)
 with open('probe_hits.csv') as fh:
     next(fh)
     for ix, ln in enumerate(fh):
         broken = ln.split(",")
         fst = broken[0].replace("WP_", "WP").split("_")[0]
         fst = fst.replace("WP", "WP_")
         snd = broken[1].replace("WP_", "WP").split(" ")[0]
         snd = snd.replace("WP", "WP_")
         qlength = int(broken[3]) - int(broken[2])
         tlength = int(broken[5]) - int(broken[4])
         to_acc = ",".join(sorted([fst, snd]))
         if ((qlength == tlength) and (qlength == 39) and (fst != snd)):
             acc[to_acc] += 1
         if (ix % 100000 == 0):
             print(ix)

 with open('probe_counts.csv', 'w') as fh:
     for key, val in acc.items():
         fh.write(key + "\n")
 #+END_SRC


** Prepare the gdf file from probe_counts.csv

|------------------+--------------|
| Inputs           | Outputs      |
|------------------+--------------|
| probe_counts.csv | clusters.gdf |
|------------------+--------------|

 #+BEGIN_SRC R :session
 
 con2 <- read_csv("probe_counts.csv", col_names=FALSE) %>%
     unite(Netw, X1, X2, sep=",") %>%
     pull(Netw)

 annotation <- read.delim("Allele.tab", sep="\t") %>%
     separate(allele_name, into=c("type"), sep="-", remove=FALSE) %>%
     mutate(size = stop - start) %>%
     select(protein_accession, type, size) %>%
     with(paste(protein_accession, type, size, sep=","))

 gdf <- c("nodedef>name VARCHAR,type VARCHAR,size DOUBLE",
          annotation,
          "edgedef>node1 VARCHAR,node2 VARCHAR",
          con2)
         
 write(gdf, "clusters.gdf")

 #+END_SRC


** Prepare also the gdf such that our primer designs are also shown in the network

*** Start by expanding our probe designs (all_probes.xlsx) into non-degenerate versions

|-----------------+----------------|
| Inputs          | Outputs        |
|-----------------+----------------|
| all_probes.xlsx | exp_probes.csv |
|-----------------+----------------|

 #+BEGIN_SRC R :session

 library(readxl)

 all_probes <-
     read_excel("all_probes.xlsx", sheet = "probes")

 exp_probes <- 
     all_probes %>%
     mutate(Exp = map(Target, expand_seq)) %>%
     unnest

 write_csv(exp_probes, "exp_probes.csv")

 #+END_SRC


*** Then filter out their target ranges using a memory-efficient Python script

|----------------+-------------------------|
| Inputs         | Outputs                 |
|----------------+-------------------------|
| exp_probes.csv | selected_probe_hits.csv |
| probe_hits.csv |                         |
|----------------+-------------------------|

 #+BEGIN_SRC python
 seq_acc = set()
 with open("exp_probes.csv") as ep:
     next(ep)
     for ix, line in enumerate(ep):
         seq = line.split(",")[4].strip()
         seq_acc.add(seq)

 probe_acc = []
 with open("probe_hits.csv") as ph:
     next(ph)
     for ix, line in enumerate(ph):
         seq = line.split(",")[6]
         if seq in seq_set:
             probe_acc.append(line)
         if (ix % 1000 == 0):
             print(ix)
        
 with open("selected_probe_hits.csv", "w") as out:
     for line in probe_acc:
         out.write(line)
 #+END_SRC


*** Process the resulting selected probe hits file "selected_probe_hits.csv" into gdf annotation

|-------------------------+--------------|
| Inputs                  | Outputs      |
|-------------------------+--------------|
| selected_probe_hits.csv | clusters.gdf |
| probe_counts.csv        |              |
| Allele.tab              |              |
|-------------------------+--------------|

 #+BEGIN_SRC R :session

 library(tidyverse)
 library(stringr)
 library(readxl)
 
 selected_hits <-
     read_csv("selected_probe_hits.csv", col_names=FALSE)

 exp_probes <-
     read_csv("exp_probes.csv")

 probe_coverage <-
     left_join(exp_probes, selected_hits, by=c("Exp" = "X7")) %>%
     select(Name, X1) %>%
     filter(complete.cases(.)) %>%
     unique %>%
     mutate(X1 = str_replace(X1, "WP_", "WP")) %>%
     separate(X1, c("Seq"), "_") %>%
     mutate(Seq = str_replace(Seq, "WP", "WP_")) %>%
     unique %>%
     group_by(Seq) %>%
     summarise(Probes = paste(sort(Name), collapse=";"))

 con2 <- read_csv("probe_counts.csv", col_names=FALSE) %>%
     unite(Netw, X1, X2, sep=",") %>%
     pull(Netw)

 annotation <-
     read.delim("Allele.tab", sep="\t") %>%
     separate(allele_name, into=c("type"), sep="-", remove=FALSE) %>%
     mutate(size = stop - start) %>%
     select(protein_accession, type, size) %>%
     left_join(probe_coverage, by=c("protein_accession" = "Seq"))

 annotation %>%
     filter(complete.cases(.),
            type != "NDM") %>%
     group_by(Probes) %>%
     summarise(n=n()) %>%
     arrange(desc(n)) %>% 
     data.frame
    
 gdf_annotation <- 
     annotation %>%
     with(paste(protein_accession, type, size, Probes, sep=","))

 gdf <- c("nodedef>name VARCHAR,type VARCHAR,size DOUBLE,probe VARCHAR",
          gdf_annotation,
          "edgedef>node1 VARCHAR,node2 VARCHAR",
          con2)
         
 write(gdf, "clusters.gdf")

 probe_targets <-
     left_join(selected_hits, exp_probes, c("X7" = "Exp")) %>%
     separate(X2, c("protein_accession", "Junk"), " ") %>%
     select(X1, protein_accession, Name) %>%
     left_join(annotation)

 multiple_targets <- 
     probe_targets %>%
     group_by(Probes, type) %>%
     summarise(n=n()) %>%
     group_by(Probes) %>%
     summarise(n=n()) %>%
     arrange(desc(n)) %>%
     filter(n > 1, complete.cases(.)) %>%
     pull(Probes)

 mult_targeting_probes <- 
     probe_targets %>%
     filter(Probes %in% multiple_targets) %>%
     group_by(Probes, type) %>%
     summarise(n=n()) %>%
     separate(Probes, c("Fst", "Snd"), ";") %>%
     select(Fst, Snd)
 mult_targeting_probes <-
     c(mult_targeting_probes$Fst, mult_targeting_probes$Snd) %>%
     unique

 all_probes <-
     read_excel("all_probes.xlsx", sheet = "probes")

 all_probes %>% mutate(
                  A = str_count(Target, "A"),
                  T = str_count(Target, "T"),
                  G = str_count(Target, "G"),
                  C = str_count(Target, "C"),
                  Non_deg = A + T + C + G) %>%
     filter(Name %in% mult_targeting_probes)

 all_probes %>% mutate(
                  A = str_count(Target, "A"),
                  T = str_count(Target, "T"),
                  G = str_count(Target, "G"),
                  C = str_count(Target, "C"),
                  Non_deg = A + T + C + G) %>%
     ggplot(aes(x=Non_deg)) +
     geom_density() +
     geom_vline(aes(xintercept=28)) +
     geom_vline(aes(xintercept=31)) +
     geom_vline(aes(xintercept=32))
 ggsave("degen_density.pdf", last_plot())

 #+END_SRC

 
* New stuff

#+BEGIN_SRC R :session

## Generate quality reports
## ls *.fastq.gz | while read file; do echo $file; fastqc $file ; done
## multiqc .

## nsearch merge --forward=NG-13024_1_lib236478_5794_7_1.fastq.gz --reverse=NG-13024_1_lib236478_5794_7_2.fastq.gz --out=NG-13024_1.fastq
## nsearch merge --forward=NG-13024_2_lib236479_5794_7_1.fastq.gz --reverse=NG-13024_2_lib236479_5794_7_2.fastq.gz --out=NG-13024_2.fastq
## nsearch merge --forward=NG-13024_3_lib236480_5794_7_1.fastq.gz --reverse=NG-13024_3_lib236480_5794_7_2.fastq.gz --out=NG-13024_3.fastq
## nsearch merge --forward=NG-13024_4_lib237853_5794_7_1.fastq.gz --reverse=NG-13024_4_lib237853_5794_7_2.fastq.gz --out=NG-13024_4.fastq
## nsearch merge --forward=NG-13024_5_lib237854_5794_7_1.fastq.gz --reverse=NG-13024_5_lib237854_5794_7_2.fastq.gz --out=NG-13024_5.fastq
## nsearch merge --forward=NG-13024_6_lib237855_5794_7_1.fastq.gz --reverse=NG-13024_6_lib237855_5794_7_2.fastq.gz --out=NG-13024_6.fastq

## ls *.fastq | grep -v lib | while read file; do nsearch filter --in $file --out filt_$file; done

## Read counts and other tabular data are provided by Python script filt_reads.py

library(tidyverse)
library(iNEXT)

mbcc <-
    read_csv("mol_bc_counts.csv") %>%
    separate(Sample_type, c("Sample", "Sample_replicate"), sep = "_") %>% 
    separate(Molecule_type, c("Stuffer", "Molecule_target", "Molecule_replicate"), sep = "_") %>% 
    filter(!(Molecule_target %in% c(9, 12)))

mol_counts <- 
    mbcc %>%
    count(Sample, Sample_replicate, Molecule_target, Molecule_replicate, name = "Count") %>% 
    mutate(Molecule_target = factor(Molecule_target, levels = as.character(c(0:10, 12:15))),
           Sample = factor(Sample, levels = as.character(c(1:11, 13:20))))

detection_limits <-
    mol_counts %>% 
    filter(Sample %in% c(3, 19, 20)) %>% 
    group_by(Molecule_target, Molecule_replicate) %>% 
    summarise(Mean = mean(Count),
              Sd = sd(Count)) %>% 
    mutate(Detlim = Mean + 3 * Sd)

concs <- 
    read_csv2("conc_gradient.csv",
              col_types = cols(
                  Sample = col_character(),
                  Molecule_target = col_character(),
                  Molecule_replicate = col_character()))

barcode_estimates <- 
    mbcc %>% 
    filter(Sample %in% 9:11) %>% 
    group_by(Sample,
             Molecule_target,
             Molecule_replicate,
             Sample_replicate) %>% 
    nest %>% 
    mutate(
        Estimate = map(data,
                     ~ iNEXT(.$Count, q = 0, datatype = "abundance") %>%
                       .$AsyEst %>%
                       as_tibble(rownames = "Measure") %>%
                       filter(Measure == "Species Richness"))) %>%
    unnest(Estimate) %>%
    select(-data) %>% 
    left_join(
        read_csv2("conc_gradient.csv",
                  col_types = cols(
                      Sample = col_character(),
                      Molecule_target = col_character(),
                      Molecule_replicate = col_character())),
        by = c("Sample",
             "Molecule_target",
             "Molecule_replicate")) %>% 
    unite(Tar_Rep, Molecule_target, Molecule_replicate,
          sep = "_", remove = FALSE)

equation_tbl <- 
    barcode_estimates %>% 
    filter(!(Tar_Rep %in% c("4_1", "3_1", "0_1", "6_2", "8_1"))) %>% 
    group_by(Tar_Rep) %>% 
    select(Molecule_concentration, Estimator, Observed) %>% 
    nest %>% 
    mutate(
        Model = map(data, ~ lm(Observed ~ Molecule_concentration, data = .)),
        Coefs = map(Model, coefficients),
        R2 = map_dbl(Model, ~ summary(.) %>% .$r.squared),
        pval = map_dbl(Model, ~ summary(.) %>% .$coefficient %>% .[2, 4])) %>% 
    select(-data, -Model) %>% 
    unnest(c(Coefs)) %>% 
    mutate(Parameter = c("Intercept", "Slope")) %>% 
    pivot_wider(
        id_cols = c("Tar_Rep", "R2", "pval"),
        names_from = "Parameter",
        values_from = "Coefs")

background_estimates <-
    mbcc %>% 
    filter(Sample %in% c(3, 19, 20)) %>% 
    group_by(Sample,
             Molecule_target,
             Molecule_replicate,
             Sample_replicate) %>% 
    nest %>% 
    mutate(
        Estimate = map(data,
                       ~ iNEXT(.$Count, q = 0, datatype = "abundance") %>%
                           .$AsyEst %>%
                         as_tibble(rownames = "Measure") %>%
                         filter(Measure == "Species Richness"))) %>%
    unnest(Estimate) %>%
    select(-data) %>% 
    ungroup %>% 
    group_by(Molecule_target, Molecule_replicate) %>% 
    summarise(Obs_Mean = mean(Observed),
              Obs_Sd = sd(Observed),
              Est_Mean = mean(Estimator),
              Est_Sd = sd(Estimator)) %>% 
    mutate(Obs_Detlim = Obs_Mean + 3 * Obs_Sd,
           Est_Detlim = Est_Mean + 3 * Est_Sd)

clust_conv <- 
    read_xlsx("Table_Gates_ProbeTargets.xlsx") %>%
    select(Cluster, `Enzyme family`) %>%
    filter(complete.cases(.)) %>%
    rename(Clust = Cluster,
           Family = `Enzyme family`) %>% 
    mutate(Clust = as.character(Clust))


background_estimates %>% 
    unite(Tar_Rep, Molecule_target, Molecule_replicate,
          sep = "_") %>% 
    left_join(equation_tbl) %>% 
    mutate(`Detection limit (molecules)` = (Obs_Detlim - Intercept) / Slope,
           `Detection limit (attomolar)` = `Detection limit (molecules)` / 6.022e23 / 1e-18) %>% 
    filter(complete.cases(.)) %>% 
    mutate_if(is.numeric, ~ round(., 3)) %>% 
    mutate(pval = ifelse(pval == 0, "< 0.001", pval)) %>% 
    separate(Tar_Rep, c("Clust", "Probe pair"), sep = "_") %>% 
    left_join(clust_conv, by = "Clust") %>% 
    select(Family, `Probe pair`, R2, pval, `Detection limit (attomolar)`) %>% 
    write_csv("probe_stats.csv")


#+END_SRC


* Re-working of Fig3

#+BEGIN_SRC R :session


## clust_conv <- 
##     read_xlsx("Table_Gates_ProbeTargets.xlsx") %>%
##     select(Cluster, `Enzyme family`) %>%
##     filter(complete.cases(.)) %>%
##     rename(Clust = Cluster,
##            Family = `Enzyme family`)

## lib10_counts <-
##     read_csv("lib10.csv") %>%
##     unique %>%
##     group_by(Sample_ix, Cluster) %>%
##     summarise(n=n()) %>%
##     spread(key=Cluster, value=n, fill=0) %>%
##     ungroup %>%
##     mutate(Sample_ix = as.factor(Sample_ix)) %>%
##     gather(Cluster, Count, -Sample_ix) %>%
##     mutate(Tube = 10) %>%
##     select(Tube, Sample_ix, Cluster, Count)

## ## Prepare count table for tube 11

## lib11_counts <-
##     rbind(
##         read_csv("lib11_1.csv"),
##         read_csv("lib11_2.csv")) %>%
##     unique %>%
##     group_by(Sample_ix, Cluster) %>%
##     summarise(n=n()) %>%
##     spread(key=Cluster, value=n, fill=0) %>%
##     ungroup %>%
##     mutate(Sample_ix = as.factor(Sample_ix)) %>%
##     gather(Cluster, Count, -Sample_ix) %>%
##     mutate(Tube = 11) %>%
##     select(Tube, Sample_ix, Cluster, Count)

## ## Merge the count tables

## lib_counts <-
##     rbind(lib10_counts, lib11_counts) %>%
##     spread(Cluster, Count, fill=0) %>%
##     gather(Cluster, Count, -Tube, -Sample_ix)  %>%
##     spread(Sample_ix, Count, fill=0) %>%
##     gather(Sample_ix, Count, -Tube, -Cluster)


## design <-
##     read_excel("expanded_libraries.xlsx") %>%
##     mutate(Entry = 1) %>%
##     select(Tube, Cluster, Tube, Sample_ix, Entry) %>%
##     unique %>%
##     spread(Cluster, Entry, fill=0) %>%
##     mutate(Sample_ix = as.factor(Sample_ix)) %>%
##     gather(Cluster, Count, -Sample_ix, -Tube) %>%
##     mutate(Mask = Count > 0) %>%
##     select(-Count)

## full_lib <-
##     left_join(lib_counts,
##               design,
##               by=c("Tube", "Sample_ix", "Cluster")) %>%
##     mutate_if(is.logical, replace_na, FALSE) %>%
##     mutate(Cluster = as.factor(Cluster))


##  conf_mask <-
##      read_xlsx("cluster_confirmation4.xlsx") %>% 
##      gather(Cf, Conf, -Sample_ix, -False1, -False2, -False3) %>%
##      select(-Cf) %>%
##      gather(Fl, False_pos, -Sample_ix, -Conf) %>%
##      select(-Fl) %>%
##      filter(!(is.na(Conf) & is.na(False_pos))) %>%
##      unique %>%
##      mutate(Category = case_when(
##                 !is.na(Conf) ~ 3,
##                 !is.na(False_pos) ~ 4)) %>%
##      gather(Type, Clust, -Sample_ix, -Category) %>%
##      filter(complete.cases(.)) %>%
##      select(-Type)

##  signal_tbl <- 
##      full_lib %>% 
##      filter(Tube == 10) %>% 
##      filter(!(Sample_ix %in% c(511, 512, 513))) %>%
##      left_join(t10_dl, by="Cluster") %>%
##      ungroup %>% 
##      mutate(Signal = ifelse(Count > ld, 1, 0),
##             Sample_ix = as.numeric(Sample_ix)) %>% 
##      separate(Cluster, c("Clust", "Repl"), sep="_") %>%
##      group_by(Sample_ix, Clust) %>%
##      mutate(Signal = ifelse(sum(Signal) == 2, 1, 0),
##             Signal = ifelse(Mask, Signal, -Signal)) %>%
##      ungroup %>%
##      mutate(Clust = as.numeric(Clust)) %>%
##      full_join(conf_mask) %>%
##      left_join(read_xlsx("sample_conversion.xlsx")) %>%
##      left_join(clust_conv) %>%
##      select(-mean_cnt, -sd_cnt, -ld) %>% 
##      mutate(Sign = case_when(
##                 Signal == -1 ~ 2,
##                 is.na(Category) ~ Signal,
##                 !is.na(Category) ~ Category),
##             Sign = ifelse(Signal == 0, 0, Sign),
##             Sign = as.factor(Sign))

##  lib1 <- 
##      full_lib %>% 
##      mutate(Count = ifelse(Mask, Count, -Count),
##             Tube = as.factor(Tube)) %>% 
##      filter(Tube == 10) %>% 
##      separate(Cluster, c("Clust", "Repl"), sep="_") %>% 
##      mutate(Sample_ix = as.numeric(Sample_ix),
##             Clust = as.numeric(Clust),
##             Count = abs(Count)) %>%
##      left_join(read_xlsx("sample_conversion.xlsx")) %>%
##      left_join(clust_conv, by = "Clust") %>% 
##      filter(Repl != 3,
##             Family != "KPC") %>% 
##      select(Family, Repl, Sample_ID, Count)

##  lib2 <-
##      signal_tbl %>%
##      select(Family, Repl, Sample_ID, Sign)

##  left_join(lib1, lib2) %>% 
##      unite(Fam_rep, Family, Repl, sep=" replicate") %>% 
##      ggplot(aes(x=Fam_rep, y=Sample_ID)) +
##      geom_tile(aes(fill=Count, color=Sign), size=1) +
##      scale_fill_gradient2(low = "blue", high = "red", mid="white") +
##      theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
##            axis.text.y = element_text(size=5))


## full_lib %>% 
##     filter(Tube == 10) %>% 
##     filter(!(Sample_ix %in% c(511, 512, 513))) %>%
##     left_join(t10_dl, by="Cluster") %>%
##     ungroup %>% 
##     mutate(Signal = ifelse(Count > ld, 1, 0),
##            Sample_ix = as.numeric(Sample_ix)) %>% 
##     separate(Cluster, c("Clust", "Repl"), sep="_")




library(tidyverse)
library(readxl)


lib10_counts <-
    read_csv("lib10.csv") %>%
    unique %>%
    group_by(Sample_ix, Cluster) %>%
    summarise(n=n()) %>%
    spread(key=Cluster, value=n, fill=0) %>%
    ungroup %>%
    mutate(Sample_ix = as.factor(Sample_ix)) %>%
    gather(Cluster, Count, -Sample_ix) %>%
    mutate(Tube = 10) %>%
    select(Tube, Sample_ix, Cluster, Count)

## Prepare count table for tube 11

lib11_counts <-
    rbind(
        read_csv("lib11_1.csv"),
        read_csv("lib11_2.csv")) %>%
    unique %>%
    group_by(Sample_ix, Cluster) %>%
    summarise(n=n()) %>%
    spread(key=Cluster, value=n, fill=0) %>%
    ungroup %>%
    mutate(Sample_ix = as.factor(Sample_ix)) %>%
    gather(Cluster, Count, -Sample_ix) %>%
    mutate(Tube = 11) %>%
    select(Tube, Sample_ix, Cluster, Count)

lib_counts <-
    rbind(lib10_counts, lib11_counts) %>%
    spread(Cluster, Count, fill=0) %>%
    gather(Cluster, Count, -Tube, -Sample_ix)  %>%
    spread(Sample_ix, Count, fill=0) %>%
    gather(Sample_ix, Count, -Tube, -Cluster)

design <-
    read_excel("expanded_libraries.xlsx") %>%
    mutate(Entry = 1) %>%
    select(Tube, Cluster, Tube, Sample_ix, Entry) %>%
    unique %>%
    spread(Cluster, Entry, fill=0) %>%
    mutate(Sample_ix = as.factor(Sample_ix)) %>%
    gather(Cluster, Count, -Sample_ix, -Tube) %>%
    mutate(Mask = Count > 0) %>%
    select(-Count)

full_lib <-
    left_join(lib_counts,
              design,
              by=c("Tube", "Sample_ix", "Cluster")) %>%
    mutate_if(is.logical, replace_na, FALSE) %>%
    mutate(Cluster = as.factor(Cluster))


 t10_dl <- 
     filter(full_lib, Tube == 10,
            Sample_ix %in% c(511, 512, 513)) %>%
     group_by(Cluster) %>% 
     summarise(mean_cnt = mean(Count, na.rm = TRUE),
               sd_cnt = sd(Count, na.rm = TRUE),
               ld = mean_cnt + 3*sd_cnt)

clust_conv <- 
    read_xlsx("Table_Gates_ProbeTargets.xlsx") %>%
    select(Cluster, `Enzyme family`) %>%
    filter(complete.cases(.)) %>%
    rename(Clust = Cluster,
           Family = `Enzyme family`) %>% 
    mutate(Clust = as.character(Clust))


sig_tbl <- 
    left_join(lib_counts, t10_dl, by = "Cluster") %>% 
    mutate(Signal = ifelse(Count > ld, 1, 0),
           Signal = as.character(Signal), 
           Sample_ix = as.numeric(Sample_ix)) %>% 
    separate(Cluster, c("Clust", "Repl"), sep="_") %>% 
    left_join(clust_conv) %>% 
    left_join(read_xlsx("sample_conversion.xlsx")) %>%
    filter(Repl != 3,
           Family != "KPC") %>% 
    select(-mean_cnt, -sd_cnt, -ld, -Tube, -Clust, -Sample_ix) %>% 
    unite(Fam_rep, Family, Repl, sep=" replicate")


ggplot(sig_tbl, aes(x=Fam_rep, y=Sample_ID)) +
    geom_tile(aes(fill=Count, color=Signal), size=1) +
    scale_fill_gradient2(low = "blue", high = "red", mid="white") +
    theme(axis.text.x = element_text(angle=45, hjust=1, size=7),
           axis.text.y = element_text(size=5))
ggsave("all_sigs.pdf", last_plot())




#+END_SRC


* 3) Session info

** Python version 3.6.7 | packaged by conda-forge | (default, Feb 25 2019, 20:30:30)

- Pandas version 0.24.1

** R version 3.5.1 (2018-07-02)
- Platform: x86_64-apple-darwin13.4.0 (64-bit)
- Running under: macOS  10.14.3

** Matrix products: default
- BLAS/LAPACK: /Users/mavatam/miniconda3/lib/R/lib/libRblas.dylib

** locale:

[1] C/UTF-8/C/C/C/C

** attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base

** other attached packages:

 [1] forcats_0.4.0     stringr_1.4.0     dplyr_0.8.0.1     purrr_0.3.1

 [5] readr_1.3.1       tidyr_0.8.3       tibble_2.0.1      ggplot2_3.1.0

 [9] tidyverse_1.2.1   plyr_1.8.4        data.table_1.12.0 iNEXT_2.0.19

** loaded via a namespace (and not attached):

 [1] Rcpp_1.0.0       cellranger_1.1.0 pillar_1.3.1     compiler_3.5.1

 [5] tools_3.5.1      jsonlite_1.6     lubridate_1.7.4  gtable_0.2.0

 [9] nlme_3.1-137     lattice_0.20-38  pkgconfig_2.0.2  rlang_0.3.1

[13] cli_1.0.1        rstudioapi_0.9.0 haven_2.1.0      withr_2.1.2

[17] xml2_1.2.0       httr_1.4.0       generics_0.0.2   hms_0.4.2

[21] grid_3.5.1       tidyselect_0.2.5 glue_1.3.0       R6_2.4.0

[25] readxl_1.3.0     reshape2_1.4.3   modelr_0.1.4     magrittr_1.5

[29] scales_1.0.0     backports_1.1.3  rvest_0.3.2      assertthat_0.2.0

[33] colorspace_1.4-0 stringi_1.3.1    lazyeval_0.2.1   munsell_0.5.0

[37] broom_0.5.1      crayon_1.3.4



* Sampling depth calculation

#+BEGIN_SRC R :session

library(tidyverse)

lib10 <- read_csv("lib10.csv")
lib11_1 <- read_csv("lib11_1.csv")
lib11_2 <- read_csv("lib11_2.csv")

bind_rows(lib10, lib11_1, lib11_2)

# This gives 1 826 715 sequences which is about 12% of the total reads (15 148 193).


bind_rows(lib10, lib11_1, lib11_2) %>% 
    count(Sample_ix) %>% 
    mutate(Read_depth = 12 * n,
           MiSeq_fraction = 30e6 / Read_depth,
           NovaSeq_fraction = 20e9 / Read_depth) %>% 
    arrange(desc(NovaSeq_fraction)) %>% 
    summarise(MiSeq_mean = mean(MiSeq_fraction),
              NovaSeq_mean = mean(NovaSeq_fraction))

# This means that the most deeply sampled bc could fit 40 times on an Illumina Reagent Kit v2 run


#+END_SRC
